# SBnovel â€” Timeâ€‘resolved sedentary behavior at national scale

This repository contains a fully reproducible pipeline to derive timeâ€‘resolved (10â€‘second, aggregated hourly) sedentary behavior from raw wrist accelerometers (NHANES 2011â€“2014) and to summarize diurnal and weekdayâ€“weekend patterns using surveyâ€‘weighted models. We combine:

- Sleep/nonâ€‘wear detection (SWaN) to identify valid wear windows
- Posture classification (DeepPostures/CHAP) in 10â€‘second windows
- Participantâ€‘level hourly summaries and batch orchestration

Background and purpose (from the abstract): Sedentary behavior is a major public health concern, but most surveillance collapses raw signals into daily summaries that obscure withinâ€‘day structure and are hard to reproduce. Our goal is to produce objective, nationally representative, timeâ€‘resolved estimates of sedentary behavior in the U.S., quantifying diurnal patterns and weekdayâ€“weekend differences via a reproducible pipeline.

Methods overview:

- Data: raw triaxial wrist accelerometer (NHANES 2011â€“2014; 14,692 participants)
- Sleep/nonâ€‘wear: SWaN model on 30â€‘second windows (WEAR, SLEEP, NONâ€‘WEAR)
- Posture: CHAP model (DeepPostures) to label 10â€‘second windows as sitting vs notâ€‘sitting; aggregated to hourly
- Alignment: Sleep expanded to 10â€‘second resolution to mask posture during sleep/nonâ€‘wear; sitting/notâ€‘sitting computed among WEAR minutes
- Analytic models: surveyâ€‘weighted mixedâ€‘effects models for national estimates across hours (performed downstream of this repoâ€™s data products)

## Environments

Preferred: use the included conda environment YAMLs for reproducibility. This pins Python and package versions so everyone gets the same binaries without solver surprises.

Create from YAML (recommended):

```bash
# Sleep / SWaN environment
conda env create -f environments/swan.yml

# Posture / DeepPostures environment
conda env create -f environments/posture.yml

# Optional: Posture (GPU) environment
conda env create -f environments/posture-gpu.yml
```

Troubleshooting: if env creation fails during the pip stage with an error like "TypeError: sequence item 0: expected str instance, dict found", update your local copy of the YAMLs. We removed a malformed pip options block; the fixed files in this repo no longer use a pip section for posture envs (all packages come from conda channels).

Troubleshooting (SWaN/NumPy): if you see errors like "module 'numpy' has no attribute 'float'", your NumPy is too new (>= 1.24 removed np.float). The sleep env is pinned to avoid this, but if your cluster solved a newer NumPy, downgrade to < 1.24:

```bash
# Preferred (conda)
conda install -n sklearn023 -c conda-forge 'numpy<1.24' -y

# Alternative (pip inside the env)
conda run -n sklearn023 pip install 'numpy<1.24'

# Verify
conda run -n sklearn023 python - <<'PY'
import numpy as np
print('numpy=', np.__version__, 'has np.float?', hasattr(np, 'float'))
PY
```

Cluster note: if you see a rollback with "No compatible shell found!", set your shell explicitly and retry:

```bash
export SHELL=/bin/bash
conda --no-plugins env create -f environments/posture-gpu.yml
```

Solver note (cluster): if the above with `--no-plugins` errors with "non-default solver backend (libmamba) not recognized", force the classic solver for this command:

```bash
export CONDA_SOLVER=classic
conda --no-plugins env create -f environments/posture-gpu.yml
```

Alternatively, you can pass the flag or set user config once:

```bash
# One-off flag
conda env create -f environments/posture-gpu.yml --solver=classic

# Or persist to your ~/.condarc (you can switch back later)
conda config --set solver classic
```

### Quick checks

```bash
conda run -n sklearn023 python scripts/sleep_scripts/sleep_classify.py --help
conda run -n deepposture python scripts/get_posture_predictions.py --help
conda run -n deepposture-gpu python -c "import torch; print(torch.__version__, torch.cuda.is_available())"
```

Update an existing env after YAML changes:

```bash
conda env update -n sklearn023 -f environments/swan.yml --prune
conda env update -n deepposture -f environments/posture.yml --prune
conda env update -n deepposture-gpu -f environments/posture-gpu.yml --prune
```

Why preferred:

- Reproducible and shareable (checked into the repo)
- Exact versions ensure compatible binary wheels
- Easier onboarding and CI usage

Alternative (manual creation): if you prefer to construct envs by hand, use the steps below.

### 1) Sleep environment (swan)

- Purpose: run `scripts/sleep_scripts/sleep_classify.py` which requires older binary wheels.
- Uses: Python 3.8, scikit-learn==0.23.2

Create it with conda (Miniforge/Miniconda recommended):

```bash
conda create -n sklearn023 python=3.8 -c conda-forge scikit-learn=0.23.2 pandas numpy scipy -y
```

Usage:

```bash
# activate
conda activate sklearn023
python scripts/sleep_scripts/sleep_classify.py --participant-id 62161 --data-dir data/raw --by-day

# or without activating
conda run -n sklearn023 python scripts/sleep_scripts/sleep_classify.py --participant-id 62161 --data-dir data/raw --by-day
```

### 2) Posture environment (posture)

- Purpose: run posture prediction (DeepPostures) which requires modern scikit-learn and PyTorch.
- Uses: Python 3.11, scikit-learn==1.5.2, torch

Create it with conda:

```bash
conda create -n deepposture python=3.11 -c conda-forge scikit-learn=1.5.2 pandas numpy pytorch=2.4.1 -y
```

Usage:

```bash
conda activate deepposture
python scripts/get_posture_predictions.py --participant-id 62161 --model CHAP_ALL_ADULTS --skip-incomplete-days

# or without activating
conda run -n deepposture python scripts/get_posture_predictions.py --participant-id 62161 --model CHAP_ALL_ADULTS --skip-incomplete-days
```

### Optional: Posture (GPU) â€” manual pip alternative

If the conda YAML for GPU fails on your system/cluster, you can create a clean env and install PyTorch CUDA 12.1 wheels directly via pip. Do not load system CUDA modules or add extra nvidia-* pip packages; the cu121 wheels bundle the CUDA runtime already.

Create a fresh env and install:

```bash
# Fresh env with Python 3.11
conda create -n deepposture-gpu python=3.11 pip -y
conda activate deepposture-gpu

# Ensure any CPU-only torch is removed (safe if not installed)
pip uninstall -y torch torchvision torchaudio || true

# Install PyTorch + CUDA 12.1 wheels from the official index
pip install --index-url https://download.pytorch.org/whl/cu121 \
  torch==2.4.1+cu121 torchvision==0.19.1+cu121 torchaudio==2.4.1+cu121

# Scientific stack
pip install scikit-learn==1.5.2 pandas numpy scipy h5py tqdm
```

Validate GPU is visible:

```bash
python - <<'PY'
import torch
print('torch', torch.__version__, 'cuda?', torch.cuda.is_available(), 'cuda', getattr(torch.version,'cuda',None))
if torch.cuda.is_available():
  print('device_count=', torch.cuda.device_count(), 'name=', torch.cuda.get_device_name(0))
PY
```

Notes:

- Donâ€™t mix with system CUDA modules (e.g., `module load cuda/...`); the cu121 wheels carry their own runtime.
- Donâ€™t install extra pip packages like `nvidia-cudnn-cu12`; theyâ€™re not needed and can conflict.
- Prefer the conda YAML (`environments/posture-gpu.yml`) when it resolves; use this pip route as a pragmatic fallback.

## Wrapper scripts (optional)

Create small wrappers so you don't need to remember env names. Add these to the repo and make them executable.

`run_sleep.sh`:

```bash
#!/usr/bin/env bash
conda run -n sklearn023 python scripts/sleep_scripts/sleep_classify.py "$@"
```

`run_posture.sh`:

```bash
#!/usr/bin/env bash
conda run -n deepposture python scripts/get_posture_predictions.py "$@"
```

Make them executable:

```bash
chmod +x run_sleep.sh run_posture.sh
```

## Notes

- If you already have the `swan` (sklearn023) environment active; use it for sleep scripts.
- Prefer `conda` for the older scikit-learn to avoid building from source.
// For reproducibility you can export environments to `environments/swan.yml` and `environments/posture.yml` with `conda env export -n <env> > environments/<name>.yml`.

## Repository structure

Key folders and files youâ€™ll interact with:

```text
SBnovel/
â”œâ”€ batches/                       # Batch lists of participants (CSV/TXT: cycle,participant_id)
â”‚  â”œâ”€ batch_1.txt
â”‚  â””â”€ ...
â”œâ”€ data/
â”‚  â”œâ”€ raw/                        # Extracted raw NHANES archives
â”‚  â”‚  â”œâ”€ 2011-12/<SEQN>/*.sensor.csv[.gz]
â”‚  â”‚  â””â”€ 2013-14/<SEQN>/...
â”‚  â”œâ”€ processed/<SEQN>/           # Dayâ€‘level ActiGraphâ€‘format CSVs (from prepare_DeepPosture_format)
â”‚  â”œâ”€ preprocessed/<SEQN>/        # DeepPostures preprocessed tensors/CSV per day
â”‚  â”œâ”€ predictions/<SEQN>/<MODEL>/ # 10â€‘second posture predictions per day (e.g., CHAP_ALL_ADULTS)
â”‚  â”œâ”€ sleep_predictions/<SEQN>/   # SWaN outputs; perâ€‘day CSVs under predictions/
â”‚  â””â”€ summaries/                  # Participant and batchâ€‘level hourly summaries
â”œâ”€ constants/
â”‚  â””â”€ participants.csv            # All (cycle, participant_id) pairs. Use in data download
â”œâ”€ scripts/
â”‚  â”œâ”€ batch_pipeline.py           # Batch runner: download â†’ sleep â†’ posture â†’ summarize â†’ append
â”‚  â”œâ”€ run_participant_pipeline.py # Single participant orchestrator (uses conda run if provided)
â”‚  â”œâ”€ download_participantPAMdata.py  # Download/extract NHANES participant archives
â”‚  â”œâ”€ prepare_DeepPosture_format.py   # Convert raw hourly .sensor.csv to dayâ€‘level ActiGraph CSVs
â”‚  â”œâ”€ get_posture_predictions.py       # Preprocess + run DeepPostures predictions
â”‚  â”œâ”€ summarize_participant.py         # Merge sleep/posture into hourly percent metrics
â”‚  â”œâ”€ make_batches_from_constants.py   # Generate deduped fixed-size batch files from constants
â”‚  â”œâ”€ sleep_scripts/
â”‚  â”‚  â””â”€ sleep_classify.py        # SWaN sleep/nonâ€‘wear classification by day
â”‚  â””â”€ posture_library/MSSE-2021/  # DeepPostures (CHAP) code & preâ€‘trained models
â”œâ”€ cluster/
â”‚  â””â”€ run_batch_unity_gpu.sh  # SLURM array batch script for Unity GPU partition
â”œâ”€ environments/
â”‚  â”œâ”€ posture.yml
â”‚  â”œâ”€ posture-gpu.yml
â”‚  â””â”€ swan.yml
â””â”€ README.md
```

## Data flow

1) Download raw archives per participant and extract into `data/raw/<cycle>/<SEQN>/`.
2) Optional: convert raw hourly `.sensor.csv` into dayâ€‘level ActiGraph CSVs at `data/processed/<SEQN>/`.
3) Preprocess to DeepPostures format at `data/preprocessed/<SEQN>/` and run CHAP predictions to `data/predictions/<SEQN>/<MODEL>/`.
4) Run SWaN sleep/nonâ€‘wear per day to `data/sleep_predictions/<SEQN>/predictions/`.
5) Summarize to hourly metrics per participant to `data/summaries/<SEQN>_sleep_posture_hourly.csv` and optionally append to a batch master CSV.

### Participants list (constants)

We provide `constants/participants.csv` with columns:

- `cycle` in {`2011-12`, `2013-14`}
- `participant_id` (SEQN)

This can be used to:

- Drive downloads programmatically
- Generate new batch files (e.g., split by N per file)
- Quickly search for SEQNs by cycle

Example to create a new 25â€‘file batch set (100 IDs each):

```bash
mkdir -p batches
tail -n +2 constants/participants.csv | split -l 100 - batches/batch_ --additional-suffix=.txt --numeric-suffixes=1
sed -i '' 's/^/2011-12,/g' batches/batch_*.txt # if your split lost cycle column, keep both columns otherwise
```

### Generate batches via helper script

Use `scripts/make_batches_from_constants.py` to create deduped, fixed-size batch files from the canonical list:

```bash
# Batches of 100 rows each, written to batches/batch_<N>.txt
python scripts/make_batches_from_constants.py --batch-size 100

# Shuffle the order with a fixed seed, 250 per batch, start numbering at 10
python scripts/make_batches_from_constants.py --batch-size 250 --shuffle --seed 42 --start-index 10

# Custom paths and naming
python scripts/make_batches_from_constants.py \
  --participants constants/participants.csv \
  --out-dir batches \
  --prefix nhanes_ \
  --batch-size 200
```

## Scripts guide

- `scripts/download_participantPAMdata.py`
  - Purpose: Download and (optionally) extract participant archives from NHANES FTP.
  - Key functions: `download_participant_archive_only`, `download_partfiles`, `batch_download_logs`.
  - Example: download and extract to `data/raw/2011-12/62161/` and remove archive after extract.
    - python scripts/download_participantPAMdata.py 62161 2011-12 data/raw/2011-12 --extract --remove-archive

- `scripts/prepare_DeepPosture_format.py`
  - Purpose: Convert raw hourly `.sensor.csv` files into dayâ€‘level ActiGraph CSVs used by DeepPostures.
  - Output: `data/processed/<SEQN>/<YYYY-MM-DD>.csv`
  - Example:
    - python scripts/prepare_DeepPosture_format.py 2011-12 62161 --dest-dir data/raw --processed-dir data/processed

- `scripts/sleep_scripts/sleep_classify.py`
  - Purpose: Run SWaN sleep/nonâ€‘wear classification by day for a participant.
  - Output: `data/sleep_predictions/<SEQN>/predictions/<YYYY-MM-DD>_sleep_predictions.csv`
  - Typical run inside the older sklearn env:
    - conda run -n sklearn023 python scripts/sleep_scripts/sleep_classify.py --participant-id 62161 --data-dir data/raw/2011-12 --output-dir data/sleep_predictions --by-day

- `scripts/get_posture_predictions.py`
  - Purpose: Preprocess and run DeepPostures/CHAP to get 10â€‘second sitting vs notâ€‘sitting predictions.
  - Finds model code under `scripts/posture_library/MSSE-2021/` and writes perâ€‘day predictions to `data/predictions/<SEQN>/<MODEL>/`.
  - Useful flags: `--model` (e.g., CHAP_ALL_ADULTS), `--skip-incomplete-days`, `--model-root` (override), `--preprocess-only`, `--predict-only`.
  - Example (modern env):
    - conda run -n deepposture python scripts/get_posture_predictions.py --participant-id 62161 --model CHAP_ALL_ADULTS --skip-incomplete-days

- `scripts/summarize_participant.py`
  - Purpose: Merge 10â€‘second posture with 30â€‘second sleep (expanded to 10â€‘second) and compute hourly percentages:
    - percent_sleep_nonwear, percent_wear, percent_sitting, percent_not_sitting
  - Output: `data/summaries/<SEQN>_sleep_posture_hourly.csv`
  - Example:
    - python scripts/summarize_participant.py --participant-id 62161 --model CHAP_ALL_ADULTS --out data/summaries/62161_sleep_posture_hourly.csv

- `scripts/run_participant_pipeline.py`
  - Purpose: Orchestrate the full participant pipeline via subprocess with optional conda env selection per step.
  - Steps: optional download â†’ sleep (SWaN) â†’ posture (DeepPostures)
  - Example (dry run):
    - python scripts/run_participant_pipeline.py --participant-id 62161 --cycle 2011-12 --dry-run
  - Example (execute, use envs, skip first/last incomplete days for both steps):
    - python scripts/run_participant_pipeline.py --participant-id 62161 --cycle 2011-12 --download --skip-incomplete-days-sleep --skip-incomplete-days-posture --sleep-conda-env sklearn023 --posture-conda-env deepposture --posture-model CHAP_ALL_ADULTS

- `scripts/batch_pipeline.py`
  - Purpose: Batchâ€‘process a list of participants: run participant pipeline, then `summarize_participant.py`, and append to a master CSV.
  - Input batch file: CSV/TXT with rows like `2011-12,62161` (ignore blank lines and `#` comments).
  - Default master CSV (compressed): `data/summaries/batch_sleep_posture_hourly.csv.gz` (gzip). Use `--no-compress-master` to write plain CSV.
  - Diskâ€‘saving default: perâ€‘participant summaries are written to a temporary file and deleted after appending to the master CSV. Pass `--keep-participant-summaries` if you want to keep each `data/summaries/<SEQN>_sleep_posture_hourly.csv` for debugging.
  - Example:
    - python scripts/batch_pipeline.py --batch-file batches/batch_1.txt --model CHAP_ALL_ADULTS --sleep-conda-env sklearn023 --posture-conda-env deepposture --download

## Quickstart

1) Create two conda environments (sleep and posture) as described above.
2) Prepare a batch file under `batches/` with lines like `2011-12,62161`.
3) Run the batch pipeline (downloads raw data as needed, runs sleep and posture, summarizes, and appends to a master file):

   - python scripts/batch_pipeline.py --batch-file batches/batch_1.txt --model CHAP_ALL_ADULTS --sleep-conda-env sklearn023 --posture-conda-env deepposture --download

4) Find outputs under:

- Sleep: `data/sleep_predictions/<SEQN>/predictions/*.csv`
- Posture: `data/predictions/<SEQN>/<MODEL>/*.csv`
- Hourly summary (per participant): `data/summaries/<SEQN>_sleep_posture_hourly.csv` (only if `--keep-participant-summaries` is used in batch mode; otherwise summaries are appended directly to the master and the temp files are removed)
- Batch master summary: `data/summaries/batch_sleep_posture_hourly.csv.gz` (gzip by default; pass `--no-compress-master` for plain CSV)

## Cluster batch (Unity GPU) ðŸ’»

We include a SLURM script to run each `batches/batch_<N>.txt` as a job array on the Unity cluster GPU partition:

- File: `cluster/run_batch_unity_gpu.slurm`
- Requests GPU partition, 4 cores, 40GB RAM, 10 days, long QoS
- Array: 25 tasks with concurrency 25 (1â€“25%25)
- Uses conda environments from this repoâ€™s YAMLs

Submit from repo root:

```bash
sbatch cluster/run_batch_unity_gpu.slurm
```

Customize by editing env names (`SLEEP_ENV`, `POSTURE_ENV`), model, or array range in the script.

### GPU posture environment on cluster

Create a CUDA-enabled posture environment using the provided YAML and validate GPU access:

```bash
# One-time: create envs on the cluster login node
conda env create -f environments/swan.yml          # sleep
conda env create -f environments/posture-gpu.yml   # posture (GPU)

# Sanity checks
conda run -n deepposture-gpu python -c "import torch; print(torch.__version__, torch.cuda.is_available())"
conda run -n deepposture-gpu python - <<'PY'
import torch
print('cuda_available=', torch.cuda.is_available())
if torch.cuda.is_available():
  print('device_count=', torch.cuda.device_count())
  print('device=', torch.cuda.get_device_name(0))
PY
```

The SLURM script requests a GPU with `#SBATCH --gpus=1` and sets `POSTURE_ENV=deepposture-gpu`. If your cluster uses different partition names or CUDA versions, adjust `-p` and the `pytorch-cuda` version in `environments/posture-gpu.yml` accordingly.

## Outputs and definitions

- Sleep CSV (per day): 30â€‘second windows with `START_TIME`, `STOP_TIME`, `STATE âˆˆ {WEAR, SLEEP, NONâ€‘WEAR}`.
- Posture CSV (per day): 10â€‘second rows with `timestamp`, `prediction âˆˆ {sitting, not-sitting}`.
- Hourly summary columns (per participant):
  - `percent_sleep_nonwear`: percent of hour in SLEEP or NONâ€‘WEAR
  - `percent_wear`: percent of hour in WEAR
  - `percent_sitting`: percent of hour in sitting during WEAR (scaled to full hour so `percent_sitting + percent_not_sitting = percent_wear`)
  - `percent_not_sitting`: complement of sitting during WEAR

## Notes on reproducibility

- Use `conda run -n <env>` to pin binary dependencies across steps.
- The YAML files (`environments/environment-swan.yml`, `environments/environment-posture.yml`) are included and preferred for setup. If you customize locally, you can export your updates:
  - conda env export -n sklearn023 > environments/environment-swan.yml
  - conda env export -n deepposture > environments/environment-posture.yml
- Batch runs will, by default, clean up participant directories after summarization to save disk; pass `--no-cleanup` to keep all intermediates.
